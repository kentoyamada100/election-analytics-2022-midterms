---
title: "03-Polling"
author: "Kento Yamada"
date: '2022-09-25'
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '/Users/kentoyamada/Documents/R-Projects/election-analytics-2022-midterms')
```

```{r load packages, include = FALSE}
library(tidyverse)
library(stargazer)
library(kableExtra)
library(gt)
```

```{r load data, include = FALSE}
# Data on GDP/quarter
gdp_df <- read_csv("analysis_data/GDP_quarterly.csv") %>%
  select(-c("...1", "...2")) # de-select unnecessary columns

# Data on RDI/quarter
rdi_df <- read_csv("analysis_data/RDI_quarterly.csv") %>%
  select(-"...1") # de-select unnecessary column

# Data on unemployment
unemp_df <- read_csv("analysis_data/unemployment_national_quarterly_final.csv") %>%
  select(-c("...1", "...2")) # de-select unnecessary columns

# Data on vote/seat share
share_df <- read_csv("analysis_data/house_popvote_seats.csv") %>%
  select(-c("...1", "AreaAll")) # de-select unnecessary columns
```

```{r clean gdp_df, include = FALSE}
# Select relevant columns
gdp_df_relevant <- gdp_df %>%
  select(year, quarter_cycle, GDPC1)

# Filter out data for Q1
gdp_df_q1 <- gdp_df_relevant %>%
  filter(quarter_cycle == 1) %>%
  # Note that election years are one year after Q1
  mutate(election_year = year + 1) %>% 
  rename(gdp_q1 = GDPC1) %>%
  select(-c(quarter_cycle, year))

# Filter out data for Q6
gdp_df_q6 <- gdp_df_relevant %>%
  filter(quarter_cycle == 6) %>%
  select(-quarter_cycle) %>%
  rename(gdp_q6 = GDPC1, election_year = year)

# Filter out data for Q7
gdp_df_q7 <- gdp_df_relevant %>%
  filter(quarter_cycle == 7) %>%
  select(-quarter_cycle) %>%
  rename(gdp_q7 = GDPC1, election_year = year)

# Merge and finalize data
gdp_df_final <- left_join(gdp_df_q7, gdp_df_q6, by = "election_year") %>%
  left_join(gdp_df_q1, by = "election_year") %>%
  mutate(gdp_q7_q6 = (gdp_q7 - gdp_q6) / gdp_q6 * 100,
         gdp_q7_q1 = (gdp_q7 - gdp_q1) / gdp_q1 * 100) %>%
  select(-c(gdp_q7, gdp_q6, gdp_q1))
```

```{r clean rdi_df, include = FALSE}
# Select relevant columns
rdi_df_relevant <- rdi_df %>%
  select(year, quarter_cycle, DSPIC_qt)

# Filter out data for Q1
rdi_df_q1 <- rdi_df_relevant %>%
  filter(quarter_cycle == 1) %>%
  # Note that election years are one year after Q1
  mutate(election_year = year + 1) %>% 
  rename(rdi_q1 = DSPIC_qt) %>%
  select(-c(quarter_cycle, year))

# Filter out data for Q6
rdi_df_q6 <- rdi_df_relevant %>%
  filter(quarter_cycle == 6) %>%
  select(-quarter_cycle) %>%
  rename(rdi_q6 = DSPIC_qt, election_year = year)

# Filter out data for Q7
rdi_df_q7 <- rdi_df_relevant %>%
  filter(quarter_cycle == 7) %>%
  select(-quarter_cycle) %>%
  rename(rdi_q7 = DSPIC_qt, election_year = year)

# Merge and finalize data
rdi_df_final <- left_join(rdi_df_q7, rdi_df_q6, by = "election_year") %>%
  left_join(rdi_df_q1, by = "election_year") %>%
  mutate(rdi_q7_q6 = (rdi_q7 - rdi_q6) / rdi_q6 * 100,
         rdi_q7_q1 = (rdi_q7 - rdi_q1) / rdi_q1 * 100) %>%
  select(-c(rdi_q7, rdi_q6, rdi_q1))
```

```{r clean unemp_df, include = FALSE}
# Select relevant columns
unemp_df_relevant <- unemp_df %>%
  select(year, quarter_cycle, UNRATE) %>%
  rename(unrate = UNRATE) %>%
  # Fix quarterly cycle 
  mutate(quarter_cycle = case_when(
    quarter_cycle == 1 ~ 5,
    quarter_cycle == 2 ~ 6,
    quarter_cycle == 3 ~ 7,
    quarter_cycle == 4 ~ 8,
    quarter_cycle == 5 ~ 1,
    quarter_cycle == 6 ~ 2,
    quarter_cycle == 7 ~ 3,
    quarter_cycle == 8 ~ 4
  ))

# Filter out data for Q1
unemp_df_q1 <- unemp_df_relevant %>%
  filter(quarter_cycle == 1) %>%
  # Note that election years are one year after Q1
  mutate(election_year = year + 1) %>%
  select(-c(quarter_cycle, year)) %>%
  rename(unrate_q1 = unrate)

# Filter out data for Q6
unemp_df_q6 <- unemp_df_relevant %>%
  filter(quarter_cycle == 6) %>%
  select(-quarter_cycle) %>%
  rename(election_year = year) %>%
  rename(unrate_q6 = unrate)

# Filter out data for Q7
unemp_df_q7 <- unemp_df_relevant %>%
  filter(quarter_cycle == 7) %>%
  select(-quarter_cycle) %>%
  rename(election_year = year) %>%
  rename(unrate_q7 = unrate)

# Merge and finalize data
unemp_df_final <- left_join(unemp_df_q7, unemp_df_q6, by = "election_year") %>%
  left_join(unemp_df_q1, by = "election_year") 
```

```{r clean share_df, include = FALSE}
# Define incumbent President's party affiliation
share_df_final <- share_df
# In a Presidential election year, share_df$president_party shows the party 
# of the candidate who won the Presidential election.
# Thus, in cases where the party that the incumbent President belongs to
# loses the Presidential election,
# share_df$president_party is different from the incumbent President's party
share_df_final$inc_pres_party <- share_df$president_party
share_df_final$inc_pres_party[which(share_df_final$year == 1952)] <- "D"
share_df_final$inc_pres_party[which(share_df_final$year == 1960)] <- "R"
share_df_final$inc_pres_party[which(share_df_final$year == 1968)] <- "D"
share_df_final$inc_pres_party[which(share_df_final$year == 1976)] <- "R"
share_df_final$inc_pres_party[which(share_df_final$year == 1980)] <- "D"
share_df_final$inc_pres_party[which(share_df_final$year == 1992)] <- "R"
share_df_final$inc_pres_party[which(share_df_final$year == 2000)] <- "D"
share_df_final$inc_pres_party[which(share_df_final$year == 2008)] <- "R"
share_df_final$inc_pres_party[which(share_df_final$year == 2016)] <- "D"
share_df_final$inc_pres_party[which(share_df_final$year == 2020)] <- "R"

share_df_final <- share_df_final %>%
  mutate(pp_vote_share = # Two-party vote share of the incumbent President's party
           case_when(inc_pres_party == "D" ~ D_majorvote_pct,
                     inc_pres_party == "R" ~ R_majorvote_pct),
         midterm = # Midterm election or not
           case_when(year %% 4 == 0 ~ FALSE,
                     year %% 4 == 2 ~ TRUE),
         pp_seat_share = # Seat share of the incumbent President's party
           case_when(inc_pres_party == "D" ~ D_seats/435,
                     inc_pres_party == "R" ~ R_seats/435)) %>%
  # Calculate incumbent President's vote/seat share in the previous election
  mutate(pp_prev_vote_share = lag(pp_vote_share),
         pp_prev_seat_share = lag(pp_seat_share)) %>%
  select(year, pp_vote_share, midterm, pp_seat_share, inc_pres_party, president_party,
         pp_prev_vote_share, pp_prev_seat_share) %>%
  rename(election_year = year)
```

```{r load new data, include = FALSE}
poll_df <- read_csv("analysis_data/GenericPolls1942_2020.csv")
```

```{r clean poll_df, include = FALSE }
poll_df <- poll_df %>%
  # Filter out election year and discard polls conducted after election
  filter(year %% 2 == 0) %>%
  filter(days_until_election > 0, days_until_election < 365) %>%
  select(year, emonth, eday, dem, rep, days_until_election) %>%
  rename(dem_poll = dem, rep_poll = rep) %>%
  # add weights
  mutate(recency = 365 - days_until_election)
```

```{r poll_df_final, include = FALSE}
poll_df_final <- poll_df %>%
  # calculate weighted average
  group_by(year) %>%
  summarize(dem_poll_weighted = weighted.mean(dem_poll, recency),
            rep_poll_weighted = weighted.mean(rep_poll, recency)) %>%
  rename(election_year = year)
```

```{r finalize df, include = FALSE}
df <- full_join(gdp_df_final, rdi_df_final, by = "election_year") %>%
  full_join(unemp_df_final, by = "election_year") %>%
  full_join(share_df_final, by = "election_year") %>%
  full_join(poll_df_final, by = "election_year")

# Calculate polling data for President's party
df <- df %>%
  mutate(pp_generic_ballot= # Two-party vote share of the incumbent President's party
           case_when(inc_pres_party == "D" ~ dem_poll_weighted,
                     inc_pres_party == "R" ~ rep_poll_weighted))
```

```{r df_2020, include = FALSE}
# Discard 2020
df_without_2020 <- df[df$election_year != 2020,]
```

## The Generic Ballot

Studies have suggested that when combined with a few other variables, the generic ballot can help predict the outcomes of House elections. Prior to the 2018 midterm elections, Abramowitz (2018) used a simple model with three variables (the generic ballot, the President’s party, and the number of seats that each party held before the election) and predicted that if Democrats maintained their early lead in the generic ballot, they would gain about 30 seats. In reality, the Democrats gained 41 seats. Similarly, based on the generic ballot and the fact that the incumbent president was a Republican, Bafumi et al. (2018) predicted that Democrats would gain 53.6% of the two-party vote. In fact, the Democrats won 54.4% of the two-party vote. 

Considering the fact that the generic ballot has proven to be a decent predictor of House elections, this week, I will include in the model the results of the generic ballot polls.

## Pollster Quality

When interpreting polls, we should take into account how reliable each poll is. Table 1 shows the ratings of pollsters determined by FiveThirtyEight. When determining these ratings, FiveThirtyEight considers factors such as how accurate each pollster has been in the past, whether the poll is partisan, how a pollsters’ forecast have compared against other polls, and the extent to which pollsters are influenced by other pollsters (Silver, 2014).

As seen in Table 1, pollsters with high ratings tend to have a low simple average error, which is the difference between the poll and the actual election result. Note that the magnitude of the simple average error does not perfectly correlate with the ratings. This could be because FiveThirtyEight also takes into account other metrics such as the difference between the poll’s error and the predicted error (Silver, 2014).

```{r Democrat vote share 2018, include = FALSE}
100 - df$pp_vote_share[df$election_year == 2018]
```

```{r download fivethirtyeight pollster rating data, include = FALSE}
# Read in data
pollster_ratings <- read.csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/pollster-ratings/2020/pollster-ratings.csv")
# Save data
write.csv(pollster_ratings, file = "analysis_data/pollster_ratings.csv")
```

```{r 538 pollster ratings, include = FALSE}
pollster_ratings_df <- pollster_ratings %>%
  group_by(X538.Grade) %>%
  summarize(count = n(),
            Races.Called.Correctly = mean(as.numeric(gsub("%", "", Races.Called.Correctly)))/100, 
            Simple.Average.Error = mean(Simple.Average.Error))

colnames(pollster_ratings_df) <- c("Rating", "Count", "Races Called Correctly", "Simple Average Error")

# Order: "A"   "A-"  "A/B" "A+"  "B"   "B-"  "B/C" "B+"  "C"   "C-"  "C/D" "C+"  "D-"  "D+"  "F"
pollster_ratings_df$Pollster <- 
  c("Survey USA, Suffolk University, CBS/NYT", #A
    "Emerson College, Siena College, Fox/Beacon/Shaw", #A-
    "University of Cincinnati (Ohio), LA Times, Georgetown University (Battleground)", #A/B
    "Marist College, Monmouth University, ABC/Washington Post", #A+
    "Public Policy Polling, YouGov, American Research Group", #B
    "Opinion Savvy/InsiderAdvantage, University of NH, Ipsos", #B-
    "RT Strategies, Tarrance Group, Pew Research Center", #B/C
    "Mason-Dixon, Quinnipiac University, CNN/Opinion Research Group", #B+
    "Harris Insights & Analytics, Gravis Marketing, We Ask America", #C
    "Mitchell Research & Communications, Change Research, Trafalgar Group", #C-
    "ccAdvertising, McLaughlin & Associates, Critical Insights", #C/D
    "Rasmussen Reports/Pulse Opinion Research, Zogby Interactive/JZ Analytics", #C+
    "SurveyMonkey, Swayable", #D-
    "Lucid, Google Surveys", #D+
    "Research 2000, Strategic Vision LLC, TCJ Research") #F

ratings_list <- c("A+", "A", "A-", "A/B", "B+", "B", "B-", "B/C", "C+", "C", "C-", "C/D",  "D+",  "D-", "F")
```

```{r include = FALSE}
pollster_ratings %>%
  filter(X538.Grade == "F") %>%
  arrange(desc(X..of.Polls))
```

```{r pollster ratings table, echo = FALSE}
pollster_ratings_df %>%
  mutate(Rating = factor(Rating, levels = ratings_list)) %>%
  arrange(Rating) %>%
  gt() %>%
  tab_header(title = "Table 1: Variation in Pollster Ratings (FiveThirtyEight)") %>%
  fmt_number(columns = 3:4, decimals = 2)
```

In addition to these ratings, FiveThirtyEight weighs polls based on the poll's recency and the sample size, and it uses an algorithm to determine the exact magnitude of the weights (Silver, 2022). For this blog post, I decided to weigh the results of generic ballot polls based on how close the poll was conducted to election day. Since polls tend to converge to a point close to the actual outcome only right before the election, I calculated the weighted average of generic polls, giving more weights to polls were conducted near election day (Gelman & King, 1993). The weights assigned to each poll is (365 – number of days the poll was conducted before election day). Note that I dropped the results of generic polls conducted prior to the election year (i.e. odd-numbered years).  Ideally, I would have liked to take into account the pollsters' ratings, but this was impossible because the data I used includes polls that were conducted in the 1940s, which makes it difficult to determine the reliability of the polls. This is one major limitation of my model. 

## Models

In Table 2, I compare the model that only takes into account economic variables with models that take into account the generic ballot. Model (1) is the same as Model (C) from last week’s blog, and the variables are gross domestic product (GDP) growth between Q6 and Q7, unemployment in Q7, and whether the election is a midterm election. In Model (2), I incorporate the generic ballot. Inspired by Abramowitz (2018), in Models (3) and (4), I include the President’s party’s vote share in the previous election. Lastly, Model (5) is exclusively based on the generic ballot as well as whether the election is a midterm election.

Not surprisingly, the generic ballot seems to be a significant predictor of the President’s party’s two-party vote share, as seen in Model (2). Comparing Model (1) with Model (2), we can see that the adjusted R-squared drastically improved from 0.197 to 0.654. Interestingly, the adjusted R-squared is even higher for Model (5), the model that excludes economic variables, which suggests that the generic ballot alone is a strong predictor of electoral outcomes. Model (3) and model (4) suggest that the President’s party’s vote share in the previous election is not a significant variable.

```{r test correlation, include = FALSE}
cor.test(df_without_2020$gdp_q7_q6, df_without_2020$rdi_q7_q6)
cor.test(df_without_2020$gdp_q7_q6, df_without_2020$unrate_q7)
cor.test(df_without_2020$rdi_q7_q6, df_without_2020$unrate_q7)
```

```{r models, include = FALSE}
model1 <- lm(pp_vote_share ~ gdp_q7_q6 + midterm + unrate_q7, 
             data = df_without_2020)
model2 <- lm(pp_vote_share ~ gdp_q7_q6 + midterm + unrate_q7 + 
               pp_generic_ballot, 
             data = df_without_2020)
model3 <- lm(pp_vote_share ~ gdp_q7_q6 + midterm + unrate_q7 + 
               pp_prev_vote_share, 
             data = df_without_2020)
model4 <- lm(pp_vote_share ~ gdp_q7_q6 + midterm + unrate_q7 + 
               pp_prev_vote_share + pp_generic_ballot, 
             data = df_without_2020)
model5 <- lm(pp_vote_share ~ midterm + pp_generic_ballot, 
             data = df_without_2020)
```

```{r regression output 1, include = FALSE}
stargazer(model1, model2, model3, model4, model5,
          type = 'html',
          title = "Table 2: Economic Variables and the Generic Ballot (1948-2018 Data)",
          dep.var.labels = "President's Party's Vote Share",
          covariate.labels = c('GDP Q6-Q7', 'Midterm', 'Unemployment Q7', 
                               'Generic Ballot', 'Previous Vote Share'),
          column.sep.width = "5pt") %>%
  save_kable(file = "static/posts/03-polling/table1.png",
             zoom = 2.5)
```

```{r include table, include = FALSE}
blogdown::build_dir("static")
```

![](table1.png)

```{r economy vs generic ballot, include = FALSE}
gdp_gb_test_1 <- cor.test(df_without_2020$gdp_q7_q6, df_without_2020$pp_generic_ballot)
```

Does Model (5) suggest that the economic variables do not matter? I would argue otherwise. I believe that people’s perceptions of the economy affect how they respond to generic ballot polls. Indeed, there is a positive correlation between GDP (Q7-Q6 growth) and the generic ballot (Correlation coeffcient: `r round(gdp_gb_test_1$estimate, 2)`, p-value: `r format(gdp_gb_test_1$p.value, scientific = TRUE, digits = 2)`)

## Model Testing

Models (2) and (5), which take into account the generic ballot, clearly seem to fit the data better than Model (1), which is based exclusively on economic variables. As seen in Figure 1, compared with Model (1), the predicted values based on Models (2) and (5) seem to more close to the actual values. Indeed, the root mean squared error (RMSE) of Model (1) is 2.932, while RMSE of Models (2) and (5) are 1.893 and 1.927, respectively.

As seen in Figure 2, when I ran 1000 runs of cross-validation for Model (5) by randomly holding out 8 observations in each iteration, I observed that the mean out-of-sample residuals tend to be around -1 to 1.

```{r predicted values vs actual values, echo = FALSE}
plot(df$election_year, df$pp_vote_share,
     type = "l",
     main = "Figure 1: Actual Values vs Predicted Values",
     xlab = "Year", ylab = "President's Party's Vote Share")

# Predicted values based on Model 1
lines(df_without_2020$election_year[complete.cases(df_without_2020$gdp_q7_q6, df_without_2020$unrate_q7)], # remove observations with NA's
       predict(model1, df_without_2020)[complete.cases(df_without_2020$gdp_q7_q6, df_without_2020$unrate_q7)], 
      col = "red", lty = "dotted") 

# Predicted values based on Model 2
lines(df_without_2020$election_year[complete.cases(df_without_2020$gdp_q7_q6, df_without_2020$unrate_q7, df_without_2020$pp_generic_ballot)], 
       predict(model2, df_without_2020)[complete.cases(df_without_2020$gdp_q7_q6, df_without_2020$unrate_q7, df_without_2020$pp_generic_ballot)],
      col = "blue") 

# Predicted values based on Model 5
lines(df_without_2020$election_year[complete.cases(df_without_2020$pp_generic_ballot)], 
       predict(model5, df_without_2020)[complete.cases(df_without_2020$pp_generic_ballot)],  
      col = "green")

# Add legend
legend(1987, 57, legend=c("Model 1: Economic Variables", "Model 2: Economy + Generic Ballot", "Model 5: Generic Ballot"),
       col=c("red", "blue", "green"), 
       lty= c(3, 1, 1), cex = 0.7)
```

```{r RMSE, include = FALSE}
# Square prediction errors, take mean, then take square root
rmse_model1 <- (model1$model$pp_vote_share - model1$fitted.values)^2 %>%
  mean() %>% sqrt()
rmse_model2 <- (model2$model$pp_vote_share - model2$fitted.values)^2 %>%
  mean() %>% sqrt()
rmse_model5 <- (model5$model$pp_vote_share - model5$fitted.values)^2 %>%
  mean() %>% sqrt()
```

```{r cross validation Model 2, include = FALSE}
set.seed(12345)
cv_model2_error <- 
  sapply(1:1000, function(i){
    # Randomly hold out 8 observations
    years_outsamp <- sample(df_without_2020$election_year[complete.cases(df_without_2020$gdp_q7_q6, df_without_2020$unrate_q7, df_without_2020$pp_generic_ballot)], 8) 
      #De-select years with missing values
    
    # Run linear regression based on the remaining observations
    outsamp_mod <- lm(pp_vote_share ~ gdp_q7_q6 + midterm + unrate_q7 + 
    pp_generic_ballot,
                    df_without_2020[!(df_without_2020$election_year %in% years_outsamp),])
    
    # Make predictions based on the model
    outsamp_pred <- predict(outsamp_mod,
                          df_without_2020[df_without_2020$election_year %in% years_outsamp,])
    
    # True values
    outsamp_true <- df_without_2020$pp_vote_share[df_without_2020$election_year 
                                                       %in% years_outsamp]
    
    mean(outsamp_pred - outsamp_true)
})
```

```{r mean out-of-sample residual plot, echo = FALSE}
# Plot mean out-of-sample residual
tibble(residual = cv_model2_error) %>%
  ggplot(., aes(residual)) + geom_histogram(breaks = seq(-4, 4, by = 0.5)) +
  labs(title = "Figure 2: Mean Out−of−Sample Residual: Model (2)",
       x = "Residual") +
  theme_bw()
```

## Prediction

Democrats and Republicans are neck-and-neck in terms of their performance in generic ballot pollsc conducted in 2022. After adjusting for the poll's recency, Democrats are supported by 43.7% while Republicans are supported about 44.0%. Note that the averages were weighted based on the recency of the polls. Based on this information as well as the economic variables that I used in last week’s blog post, Model (2) suggests that Democrats will gain about 43.88% of two-party vote. Model (5) predicts similar outcomes. Interestingly, compared to Model (1),both Models (2) and (5) seem to predict a more favorable outcome for Democrats, which suggests that there is a chance that Democrats could perform better than expected despite the economic conditions that favor the Republicans.

```{r load 2022 generic ballot data, include = FALSE}
recent_generic_df <- read_csv("analysis_data/538_generic_poll_2022.csv")
# subtract end date
```

```{r clean 2022 generic ballot data, include = FALSE}
recent_generic_df <- recent_generic_df %>%
  select(enddate, adjusted_dem, adjusted_rep) %>%
  mutate(enddate = as.Date(enddate, "%m/%d/%y")) %>%
  mutate(days_until_election = round(difftime("2022-11-8", enddate, units = "days"))) %>%
  # Filter out 2022
  filter(enddate >= "2022-01-01") %>%
  rename(dem_poll = adjusted_dem, rep_poll = adjusted_rep) %>%
  # add weights
  mutate(recency = as.numeric(365 - days_until_election))
```

```{r recent_generic_df, include = FALSE}
recent_generic_final <- recent_generic_df %>%
  # calculate weighted average
  summarize(dem_poll_weighted = weighted.mean(dem_poll, recency),
            rep_poll_weighted = weighted.mean(rep_poll, recency))
```

```{r predictions, include = FALSE}
# Get data for 2022
latest_data <- 
  data.frame(midterm = TRUE, 
             gdp_q7_q6 =
               # Data for Q7 is not available yet -> Calculate Q6-Q5
               # GDP in the Q2 of 2022 (i.e. Q6)
               (gdp_df_relevant$GDPC1[gdp_df_relevant$year == 2022][2] -
               # GDP in the Q1 of 2022 (i.e. Q5)
               gdp_df_relevant$GDPC1[gdp_df_relevant$year == 2022][1])/
               gdp_df_relevant$GDPC1[gdp_df_relevant$year == 2022][1],
             unrate_q7 =
               # Data for Q7 is not available yet -> Use Q6 data
               unemp_df_relevant$unrate[unemp_df_relevant$year == 2022][2],
             pp_generic_ballot = recent_generic_final$dem_poll_weighted)
```

```{r generic ballot, include = FALSE}
recent_generic_final
```


```{r make predictions, include = FALSE}
model1_pred <- predict(model1, latest_data, interval = "prediction")
model2_pred <- predict(model2, latest_data, interval = "prediction")
model5_pred <- predict(model5, latest_data, interval = "prediction")
```

```{r model evaluation and prediction, include = FALSE}
model_eval <- as.data.frame(
  matrix(
    c("1: Economic Variables", summary(model1)$adj.r.squared, rmse_model1, model1_pred,
      "2: Economy + Generic Ballot", summary(model2)$adj.r.squared, rmse_model2, model2_pred,
      "5: Generic Ballot", summary(model5)$adj.r.squared, rmse_model5, model5_pred),
    ncol = 6, byrow = TRUE))
# Label columns
names(model_eval) <- c("Model", "Adjusted R-squared", "RMSE", 
                       "Fitted", 
                       "Lower", 
                       "Upper")
# Convert to numeric
model_eval[,2] <- as.numeric(model_eval[,2])
model_eval[,3] <- as.numeric(model_eval[,3])
model_eval[,4] <- as.numeric(model_eval[,4])
model_eval[,5] <- as.numeric(model_eval[,5])
model_eval[,6] <- as.numeric(model_eval[,6])

# Limit to 4 digits
model_eval <- mutate_if(model_eval, is.numeric, format, digits= 4) 
```

```{r make table, echo = FALSE}
# Plot table
gt(model_eval) %>%
  tab_header(title = "Table 3: Model Testing and Prediction for 2022") %>%
  tab_spanner(
    label = "Model Evaluation",
    columns = 2:3
  ) %>%   
  tab_spanner(
    label = "Predictions",
    columns = 4:6
  )
```


## References
Abramowitz, A. (2018). Will Democrats Catch a Wave? The Generic Ballot Model and the 2018 US House Elections. *PS: Political Science & Politics, 51*(S1), 4-6. doi:10.1017/S1049096518001567

Bafumi, J., Erikson, R., & Wlezien, C. (2018). Forecasting the 2018 Midterm Election using National Polls and District Information. *PS: Political Science & Politics, 51*(S1), 7-11. doi:10.1017/S1049096518001579


Gelman, A., & King, G. (1993). Why Are American Presidential Election Campaign Polls So Variable When Votes Are So Predictable? *British Journal of Political Science, 23*(4), 409–451. https://doi.org/10.1017/S0007123400006682


Silver, N. (2014, September 25). How FiveThirtyEight calculates pollster ratings. *FiveThirtyEight.*  https://fivethirtyeight.com/features/how-fivethirtyeight-calculates-pollster-ratings/ 

Silver, N. (2022, June 30). How FiveThirtyEight’s House, Senate and governor models work. *FiveThirtyEight.*  https://fivethirtyeight.com/methodology/how-fivethirtyeights-house-and-senate-models-work/

