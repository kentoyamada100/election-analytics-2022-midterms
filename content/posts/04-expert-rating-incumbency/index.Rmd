---
title: "04-Expert Ratings and Incumbency"
author: "Kento Yamada"
date: "2022-10-03"
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE)
knitr::opts_knit$set(root.dir = '/Users/kentoyamada/Documents/R-Projects/election-analytics-2022-midterms')
```

```{r pull functions, include = FALSE}
setwd("R")
files.sources = list.files()
sapply(files.sources, source)
setwd("..")
```

```{r load packages, include = FALSE}
library(tidyverse)
library(sf)
library(gridExtra)  
library(rmapshaper)
library(tigris)
library(stargazer)
library(kableExtra)
library(plotly)
```

## Expert Ratings

Unlike my models in my previous blogs, which focused exclusively on variables at the national level, organizations such as Cook Political Report and Sabato’s Crystal Ball also take into account local conditions when determining the ratings for each district. Their track record has been impressive: expert ratings alone have accurately predicted 96.6% of House elections held between 1998 and 2016 (Silver, 2022). Thus, it is no surprise that expert predictions are often included in models designed to predict House elections (Campbell, 2018b; Silver, 2022). In the first part of this blog post, I will analyze the expert ratings from 2018 and compare them with the actual vote share.

```{r load data, include = FALSE}
vote_share <- read_csv("analysis_data/house_party_vote_share_by_district_1948-2020.csv")
expert_rating <- read_csv("analysis_data/expert_rating.csv")
```

```{r download shapefile for 114th Congress, eval = FALSE, include = FALSE}
cd114 <- get_congress_map(114) 
```

```{r edit shapefile, include = FALSE}
cd114 <- readRDS("analysis_data/districts114.rds") %>%
  
  # Select columns, rename, and convert district number to numeric
  select(STATENAME, DISTRICT) %>%
  rename(district_num = DISTRICT, State = STATENAME) %>%
  mutate(district_num = as.numeric(district_num))
```

```{r 2018 two-party vote share margin by CD, include = FALSE}
vote_share_2018 <- vote_share %>%
  
  # Filter out 2018 data
  filter(raceYear == 2018) %>%
  select(State, district_num, district_id, RepVotesMajorPercent, DemVotesMajorPercent, WinnerParty) %>%
  
  # Rename columns
  rename(pct_R = RepVotesMajorPercent, pct_D = DemVotesMajorPercent, id = district_id)
```

```{r fix data for Maine, include = FALSE}
vote_share_2018_df <- 
  bind_rows(
    # States except for Maine
    vote_share_2018[vote_share_2018$State != "Maine",],
    
    # Maine CD 1
    vote_share_2018[vote_share_2018$State == "Maine" & vote_share_2018$district_num == 1,],
    
    # Maine CD 2
    # Jared Golden (D) won due to ranked-choice voting
    vote_share_2018[vote_share_2018$State == "Maine" & vote_share_2018$district_num == 2,][2,]
  )
```

Note that the vote share for Maine's 2nd Congressional District shows the vote share that was adjusted as part of Maine's ranked-choice voting system.


```{r 2018 expert ratings, include = FALSE}
expert_rating_2018 <- expert_rating %>%
  # Filter out 2018
  filter(year == 2018) %>%
  # Rename column
  rename(State = state, district_num = district) %>%
  # Drop NA columns
  select_if(~ !any(is.na(.))) %>%
  select(-year) %>%
  # Round average ratings
  mutate(avg_rating = round(avg_rating, 2))
```

```{r clean 2018 expert ratings data , include = FALSE}
# Alaska: District number -> 0
expert_rating_2018$district_num[expert_rating_2018$State == "Alaska"] <- 0
expert_rating_2018$district_num[expert_rating_2018$State == "Montana"] <- 0
# Convert to numeric
expert_rating_2018$district_num <- as.numeric(expert_rating_2018$district_num)
```


```{r merge shapefile with election results data, include = FALSE}
map_2018 <- cd114 %>% 
  left_join(vote_share_2018_df, by = c("State", "district_num")) %>%
  left_join(expert_rating_2018, by = c("State", "district_num"))
```

```{r clean vote_share_2018_map, include = FALSE}
map_2018 <- map_2018 %>%
  ms_simplify(keep = 0.04) %>% # Simplify geometry
  shift_geometry(position = "outside") %>% # Move Alaska and Hawaii
  st_cast("MULTIPOLYGON")
```

Figure 1 shows the share of the two-party vote that Democratic candidates won in each district in the 2018 House elections. The map is based on the shapefile obtained from Lewis et al. (2020). Note that the vote share for Maine’s 2nd District shows the vote share that was adjusted as part of Maine’s ranked-choice voting system. As I noted in Blog Post 1, even after considering the fact that some races are uncontested, many districts are colored in dark colors, which suggests that candidates in most districts won by sizable margins. 
```{r Democratic vote share in 2018, echo = FALSE, message = FALSE, warning = FALSE}
d_vote_share_map_2018 <- ggplot(data = map_2018) +
  
  # Plot Democrat vote share
  geom_sf(aes(fill = pct_D,  label = id), color = "grey30", size = 0.05) +

  # Change color based on seat share
  scale_fill_gradient2(low = "red", 
                       mid = "white", 
                       high = "blue", 
                       midpoint = 50,
                       name = "Democratic Vote Share") +

 labs(title = "Figure 1: Democratic Vote Share by District (2018 House)") +
  
 # Set theme
 theme(axis.line = element_blank(), axis.text = element_blank(),
       axis.ticks = element_blank(), axis.title = element_blank(),
       panel.background = element_blank())
```

```{r figure 1, echo = FALSE}
ggplotly(d_vote_share_map_2018, tooltip = c("id", "pct_D"))
```

Figure 2 shows the average of expert predictions made by 6 organizations: Cook Political report, The Rothenberg Political Report, Sabato’s Crystal Ball, Real Clear Politics, Daily Kos, and FiveThirtyEight. The ratings are on a 7-point scale, with 7 being “solid Republican,” 4 being “toss up,” and 1 being “solid Democrat,” and I took the average of the ratings in each district. One limitation of this approach is that those categories may be defined differently by the 6 organizations. I later address this issue by comparing how the average of the 7-point scale translate into actual vote shares.

```{r expert ratings in 2018, echo = FALSE, message = FALSE, warning = FALSE}
expert_rating_map_2018 <- ggplot(data = map_2018) +
  
  # Plot Democrat vote share
  geom_sf(aes(fill = avg_rating, label = id), color = "grey30", size = 0.05) +

  # Change color based on seat share
  scale_fill_gradient2(low = "blue", 
                       mid = "white", 
                       high = "red", 
                       midpoint = 4,
                       na.value = "black",
                       name = "Ratings") +

 labs(title = "Figure 2: Average Expert Ratings (2018 House)") +
  
 # Set theme
 theme(axis.line = element_blank(), axis.text = element_blank(),
       axis.ticks = element_blank(), axis.title = element_blank(),
       panel.background = element_blank())
```

```{r figure 2, echo = FALSE}
ggplotly(expert_rating_map_2018)
```

Ratings were unavailable in most districts as analysts presumably focus on competitive races. The districts colored in black show the districts where ratings were unavailable, which again highlights the fact that most seats are safe seats. Also, among the districts where ratings were available, many were classified as “solid” or “lean” Democrat or Republican, as seen by the dark blue/red colors.


How accurate were these ratings? To answer this question, I start by translating the 7-point scale of the expert ratings into vote shares. As seen in Figure 3, in each of the 7 categories, the actual vote shares tended to be within 5 to 10 percentage points of the mean of the actual vote share in each category. This alone suggests that expert ratings tended to be quite accurate. 


```{r analyze full 2018 data, include = FALSE}
map_2018_data <- st_drop_geometry(map_2018) %>%
  # Focus on districts where there was average ratings
  drop_na(avg_rating) %>%
  as_tibble() 
```

```{r make avg_ratings discrete, include = FALSE}
map_2018_data$rating_range <- cut_width(map_2018_data$avg_rating,
                                        width = 1, boundary = 0.5)
```

```{r plot ratings vs actual vote share, echo = FALSE, warning = FALSE}
p3 <- map_2018_data %>%
  group_by(rating_range) %>%
  mutate(mean_pct_D = mean(pct_D)) %>%
  ggplot() +
    geom_histogram(aes(x = pct_D), binwidth = 1) +
    geom_vline(aes(xintercept = mean_pct_D), color = "purple") +
    facet_wrap(~rating_range) +
  labs(title = "Figure 3: Expert Ratings vs Actual Democratic Vote Share",
       x = "Democratic Vote Share", y = NULL)
```

```{r vote share per category, include = FALSE}
pct_D_per_category <- map_2018_data %>%
  group_by(rating_range) %>%
  summarize(mean_pct_D = round(mean(pct_D), 2))
# Specify where to plot on map
pct_D_per_category$y <- rep(7.5, 7)
pct_D_per_category$mean <- paste0("Mean: ", pct_D_per_category$mean_pct_D)
```

```{r Figure 3, echo = FALSE}
p3 +
  # Add labels
  geom_text(data = pct_D_per_category,
            mapping = aes(x = mean_pct_D + 1, y = y, 
                          label = mean), color = "purple")
```

To calculate the difference between the ratings and the actual vote shares, I decided to convert the expert ratings to the mean of the actual vote share of each category shown in Figure 3. As seen in Figure 4, the expert predictions were remarkably accurate, as seen by the fact that the difference between the ratings and the actual vote shares tended to be within 1 to 2 points. There were very few districts where candidates performed significantly better than expected. There were only three districts where the error was larger than 5 points: Pennsylvania’s 5th district (difference: -6.70), New York’s 11th district (difference: -5.52), and Florida’s 25th District (difference: 6.44). 

```{r turn expert ratings into numeric variables, include = FALSE}
map_2018 <- map_2018 %>%
  mutate(rating_range = 
           # Specify categories of ratings
           cut_width(map_2018$avg_rating, width = 1, boundary = 0.5)) %>%
  mutate(rating_numeric =
           case_when(
             # Match mean values with their respective categories
             rating_range == "[0.5,1.5]" ~ pct_D_per_category$mean_pct_D[1],
             rating_range == "(1.5,2.5]" ~ pct_D_per_category$mean_pct_D[2],
             rating_range == "(2.5,3.5]" ~ pct_D_per_category$mean_pct_D[3],
             rating_range == "(3.5,4.5]" ~ pct_D_per_category$mean_pct_D[4],
             rating_range == "(4.5,5.5]" ~ pct_D_per_category$mean_pct_D[5],
             rating_range == "(5.5,6.5]" ~ pct_D_per_category$mean_pct_D[6],
             rating_range == "(6.5,7.5]" ~ pct_D_per_category$mean_pct_D[7]
           )) %>%
  # Calculate difference between rating and actual vote share
  mutate(rating_pct_D = rating_numeric - pct_D)
```

```{r expert ratings vs actual in 2018, echo = FALSE, message = FALSE, warning = FALSE}
rating_vs_actual_map_2018 <- ggplot(data = map_2018) +
  
  # Plot Democrat vote share
  geom_sf(aes(fill = rating_pct_D, label = id), color = "grey30", size = 0.05) +

  # Change color based on seat share
  scale_fill_gradient2(low = "red", 
                       mid = "white", 
                       high = "blue", 
                       midpoint = 0,
                       na.value = "black",
                       name = "Difference") +

 labs(title = "Figure 4: Difference between Expert Ratings and Actual Vote Share") +
  
 # Set theme
 theme(axis.line = element_blank(), axis.text = element_blank(),
       axis.ticks = element_blank(), axis.title = element_blank(),
       panel.background = element_blank())
```

```{r figure 4, echo = FALSE}
ggplotly(rating_vs_actual_map_2018)
```

```{r count districts in which Democrats did better than expected, include = FALSE}
map_2018 %>%
  filter(rating_pct_D >= 0) %>%
  nrow()

map_2018 %>%
  filter(rating_pct_D < 0) %>%
  nrow()
```


## Incumbency

In the second half of this blog post, I focus on incumbency, focusing on the incumbency of the candidates as well as the party that the incumbent President belongs to. On one hand, incumbent candidates tend to perform well, as seen from the fact that typically, over 90% of House incumbents who seek re-election end up winning due to structural advantages (Brown, 2014, pp. 133-134). On the other hand, the incumbent President’s party typically loses seats in midterm elections (Campbell, 2018a, p. 1, p.1). To take into account these factors, I build a model based on the following four variables. Note that the dependent variable is the Democratic seat share.

#### Democrat’s performance in the generic ballot
As seen in Blog Post 3, the generic ballot is highly predictive of electoral outcomes.

#### Whether the sitting President is a Democrat or not
Having a Democratic President should result in a decrease in the Democratic seat share, especially in midterm elections.

#### Democrat’s seat share in the previous election
If House incumbents tend to win election, winning more seats in the previous election should result in a higher seat share in the current election.

#### Whether the economy has been doing poorly
Inspired by Folke & Snyder (2012), I hypothesize that the effect of having a Democratic president may depend on the state of the economy. I expect that having Democratic president who presides over a poor economy will result in a seat loss for the Democrats. Similar to Folke & Snyder (2012), I create a dichotomous variable, with 1 representing poor economic performance. Since I saw in blog post 2 that Q7-Q8 GDP growth helps to predict electoral outcomes, I define a poor economy as a state in which the Q7-Q8 GDP growth is below the average of that between 1948 and 2018.


```{r load data 2, include = FALSE}
# Data on GDP/quarter
gdp_df <- read_csv("analysis_data/GDP_quarterly.csv") %>%
  select(-c("...1", "...2")) # de-select unnecessary columns

# Data on RDI/quarter
rdi_df <- read_csv("analysis_data/RDI_quarterly.csv") %>%
  select(-"...1") # de-select unnecessary column

# Data on unemployment
unemp_df <- read_csv("analysis_data/unemployment_national_quarterly_final.csv") %>%
  select(-c("...1", "...2")) # de-select unnecessary columns

# Data on vote/seat share
share_df <- read_csv("analysis_data/house_popvote_seats.csv") %>%
  select(-c("...1", "AreaAll")) # de-select unnecessary columns
```

```{r clean gdp_df, include = FALSE}
# Select relevant columns
gdp_df_relevant <- gdp_df %>%
  select(year, quarter_cycle, GDPC1)

# Filter out data for Q1
gdp_df_q1 <- gdp_df_relevant %>%
  filter(quarter_cycle == 1) %>%
  # Note that election years are one year after Q1
  mutate(election_year = year + 1) %>% 
  rename(gdp_q1 = GDPC1) %>%
  select(-c(quarter_cycle, year))

# Filter out data for Q6
gdp_df_q6 <- gdp_df_relevant %>%
  filter(quarter_cycle == 6) %>%
  select(-quarter_cycle) %>%
  rename(gdp_q6 = GDPC1, election_year = year)

# Filter out data for Q7
gdp_df_q7 <- gdp_df_relevant %>%
  filter(quarter_cycle == 7) %>%
  select(-quarter_cycle) %>%
  rename(gdp_q7 = GDPC1, election_year = year)

# Merge and finalize data
gdp_df_final <- left_join(gdp_df_q7, gdp_df_q6, by = "election_year") %>%
  left_join(gdp_df_q1, by = "election_year") %>%
  mutate(gdp_q7_q6 = (gdp_q7 - gdp_q6) / gdp_q6 * 100,
         gdp_q7_q1 = (gdp_q7 - gdp_q1) / gdp_q1 * 100) %>%
  select(-c(gdp_q7, gdp_q6, gdp_q1))

# Define new variable `poor_econ`
# First calculate 1948-2018 mean
mean_gdp_q7_q6 <- mean(gdp_df_final$gdp_q7_q6[gdp_df_final$election_year != 2020])
gdp_df_final <- gdp_df_final %>%
  mutate(poor_econ = case_when(
    # 1 if worse than 1948-2018 average
     gdp_q7_q6 < mean_gdp_q7_q6 ~ TRUE,
     gdp_q7_q6 >= mean_gdp_q7_q6 ~ FALSE,
  ))
```

```{r clean rdi_df, include = FALSE}
# Select relevant columns
rdi_df_relevant <- rdi_df %>%
  select(year, quarter_cycle, DSPIC_qt)

# Filter out data for Q1
rdi_df_q1 <- rdi_df_relevant %>%
  filter(quarter_cycle == 1) %>%
  # Note that election years are one year after Q1
  mutate(election_year = year + 1) %>% 
  rename(rdi_q1 = DSPIC_qt) %>%
  select(-c(quarter_cycle, year))

# Filter out data for Q6
rdi_df_q6 <- rdi_df_relevant %>%
  filter(quarter_cycle == 6) %>%
  select(-quarter_cycle) %>%
  rename(rdi_q6 = DSPIC_qt, election_year = year)

# Filter out data for Q7
rdi_df_q7 <- rdi_df_relevant %>%
  filter(quarter_cycle == 7) %>%
  select(-quarter_cycle) %>%
  rename(rdi_q7 = DSPIC_qt, election_year = year)

# Merge and finalize data
rdi_df_final <- left_join(rdi_df_q7, rdi_df_q6, by = "election_year") %>%
  left_join(rdi_df_q1, by = "election_year") %>%
  mutate(rdi_q7_q6 = (rdi_q7 - rdi_q6) / rdi_q6 * 100,
         rdi_q7_q1 = (rdi_q7 - rdi_q1) / rdi_q1 * 100) %>%
  select(-c(rdi_q7, rdi_q6, rdi_q1))
```

```{r clean unemp_df, include = FALSE}
# Select relevant columns
unemp_df_relevant <- unemp_df %>%
  select(year, quarter_cycle, UNRATE) %>%
  rename(unrate = UNRATE) %>%
  # Fix quarterly cycle 
  mutate(quarter_cycle = case_when(
    quarter_cycle == 1 ~ 5,
    quarter_cycle == 2 ~ 6,
    quarter_cycle == 3 ~ 7,
    quarter_cycle == 4 ~ 8,
    quarter_cycle == 5 ~ 1,
    quarter_cycle == 6 ~ 2,
    quarter_cycle == 7 ~ 3,
    quarter_cycle == 8 ~ 4
  ))

# Filter out data for Q1
unemp_df_q1 <- unemp_df_relevant %>%
  filter(quarter_cycle == 1) %>%
  # Note that election years are one year after Q1
  mutate(election_year = year + 1) %>%
  select(-c(quarter_cycle, year)) %>%
  rename(unrate_q1 = unrate)

# Filter out data for Q6
unemp_df_q6 <- unemp_df_relevant %>%
  filter(quarter_cycle == 6) %>%
  select(-quarter_cycle) %>%
  rename(election_year = year) %>%
  rename(unrate_q6 = unrate)

# Filter out data for Q7
unemp_df_q7 <- unemp_df_relevant %>%
  filter(quarter_cycle == 7) %>%
  select(-quarter_cycle) %>%
  rename(election_year = year) %>%
  rename(unrate_q7 = unrate)

# Merge and finalize data
unemp_df_final <- left_join(unemp_df_q7, unemp_df_q6, by = "election_year") %>%
  left_join(unemp_df_q1, by = "election_year") 
```

```{r clean share_df, include = FALSE}
# Define incumbent president's party affiliation
share_df_final <- share_df
# In a Presidential election year, share_df$president_party shows the party 
# of the candidate who won the Presidential election.
# Thus, in cases where the party that the incumbent president belongs to
# loses the Presidential election,
# share_df$president_party is different from the incumbent president's party
share_df_final$inc_pres_party <- share_df$president_party
share_df_final$inc_pres_party[which(share_df_final$year == 1952)] <- "D"
share_df_final$inc_pres_party[which(share_df_final$year == 1960)] <- "R"
share_df_final$inc_pres_party[which(share_df_final$year == 1968)] <- "D"
share_df_final$inc_pres_party[which(share_df_final$year == 1976)] <- "R"
share_df_final$inc_pres_party[which(share_df_final$year == 1980)] <- "D"
share_df_final$inc_pres_party[which(share_df_final$year == 1992)] <- "R"
share_df_final$inc_pres_party[which(share_df_final$year == 2000)] <- "D"
share_df_final$inc_pres_party[which(share_df_final$year == 2008)] <- "R"
share_df_final$inc_pres_party[which(share_df_final$year == 2016)] <- "D"
share_df_final$inc_pres_party[which(share_df_final$year == 2020)] <- "R"

share_df_final <- share_df_final %>%
  # Democrat two-party vote share
  rename(D_vote_share = D_majorvote_pct) %>%
  mutate(
    # Midterm election or not
    midterm = case_when(year %% 4 == 0 ~ FALSE,
                     year %% 4 == 2 ~ TRUE),
    # Democrat seat share
    D_seat_share = D_seats/435,
    # Whether incumbent president is Democrat
    D_pres = case_when(
      inc_pres_party == "D" ~TRUE,
      inc_pres_party == "R" ~FALSE,
    )) %>%
  # Calculate incumbent President's vote/seat share in the previous election
  mutate(D_prev_vote_share = lag(D_vote_share),
         D_prev_seat_share = lag(D_seat_share)) %>%
  select(year, midterm, D_vote_share, D_seat_share, inc_pres_party, president_party, D_pres,
         D_prev_vote_share, D_prev_seat_share) %>%
  rename(election_year = year)
```

```{r load new data, include = FALSE}
poll_df <- read_csv("analysis_data/GenericPolls1942_2020.csv")
```

```{r clean poll_df, include = FALSE }
poll_df <- poll_df %>%
  # Filter out election year and discard polls conducted after election
  filter(year %% 2 == 0) %>%
  filter(days_until_election > 0, days_until_election < 365) %>%
  select(year, emonth, eday, dem, rep, days_until_election) %>%
  rename(dem_poll = dem, rep_poll = rep) %>%
  # add weights
  mutate(recency = 365 - days_until_election)
```

```{r poll_df_final, include = FALSE}
poll_df_final <- poll_df %>%
  # calculate weighted average
  group_by(year) %>%
  summarize(dem_poll_weighted = weighted.mean(dem_poll, recency),
            rep_poll_weighted = weighted.mean(rep_poll, recency)) %>%
  rename(election_year = year)
```

```{r finalize df, include = FALSE}
df <- full_join(gdp_df_final, rdi_df_final, by = "election_year") %>%
  full_join(unemp_df_final, by = "election_year") %>%
  full_join(share_df_final, by = "election_year") %>%
  full_join(poll_df_final, by = "election_year")
```

```{r df_2020, include = FALSE}
# Discard 2020
df_without_2020 <- df[df$election_year != 2020,]
```


```{r model 1, include = FALSE}
model1 <- lm(D_seat_share ~ dem_poll_weighted + D_pres, 
              data = df_without_2020)
```

```{r model 2, include = FALSE}
model2 <- lm(D_seat_share ~ dem_poll_weighted + D_pres + D_prev_seat_share, 
              data = df_without_2020)
```


```{r model 3, include = FALSE}
model3 <- lm(D_seat_share ~ dem_poll_weighted + D_pres*poor_econ + D_prev_seat_share, 
              data = df_without_2020)
```


```{r model 4, include = FALSE}
model4 <- lm(D_seat_share ~ dem_poll_weighted + D_pres*poor_econ + D_prev_seat_share, 
              data = df_without_2020 %>% filter(midterm == TRUE))
```


```{r regression output 1, include = FALSE}
stargazer(model1, model2, model3, model4,
          type = 'html',
          title = "Table 1: Incumbency, Economic Variables, and the Generic Ballot (1948-2018 Data)",
          dep.var.labels = "Democratic Seat Share",
          covariate.labels = c('Generic Ballot', 'Democratic President', 'Poor Economic Performance', 
                               'Previous Seat Share', '(Democrat President) x (Poor Economic Performance)'),
          column.labels = c("All 1948-2018 Elections", "Midterms Only"),
          column.separate = c(3, 1),
          column.sep.width = "5pt") %>%
  save_kable(file = "static/posts/04-expert-rating-incumbency/table1.png",
             zoom = 2.5)
```

```{r include table, include = FALSE}
blogdown::build_dir("static")
```

![](table1.png)

Models (1) and (2) suggest that having a Democratic President has a negative and significant effect on the Democratic seat share while a higher seat share gained in the previous election has a positive and significant effect. This confirms the notion that incumbents tend to perform well but that the party of the incumbent President tends to perform poorly. Model (3) suggests that the interaction between the President’s party affiliation and the state of the economy is not statistically significant. In Model (4), I focused on midterm elections to see whether the effects of the President’s party affiliation and the state of the economy are larger. The results confirm that the President’s party tends to lose seats in midterm elections, but we do not see evidence of any significant interaction between the President’s party affiliation and the state of the economy. I believe there are two reasons for this. First, voters may be willing to penalize the President’s party regardless of the state of the economy, as suggested by the fact that the President’s party almost always loses seats in midterm elections. As Fokle & Snyder (2012) imply, voters may simply want to counteract the results of previous presidential election. Second, economic variables may not be a good predictor. As noted in Blog Post 03, the generic ballot alone can be used to predict outcomes. Voters presumably do care about the state of the economy, and they likely take into account the state of the economy when answering generic ballot polls. However, it seems that economic variables do not help improve the models.

### References


Brown, A. R. (2014). Voters Don't Care Much About Incumbency. *Journal of Experimental Political Science, 1*(2), 132–143. https://doi.org/10.1017/xps.2014.6

Campbell, J.E. (2018a). Introduction: Forecasting the 2018 US Midterm Elections. *PS: Political Science & Politics, 51*(S1), 1-3. doi:10.1017/S1049096518001592

Campbell, J.E. (2018b). The Seats-in-Trouble Forecasts of the 2018 Midterm Congressional Elections. *PS: Political Science & Politics, 51*(S1), 12–16. https://doi.org/10.1017/S1049096518001580

Folke, O. & Snyder, J. M. (2012). Gubernatorial Midterm Slumps. *American Journal of Political Science, 56*(4), 931–948. https://doi.org/10.1111/j.1540-5907.2012.00599.x

Lewis, J. B., DeVine, B., Pitcher, L., & Martis, K. C. (2020). *Digital Boundary Definitions of United States Congressional Districts* (Version 1.5) [Data file]. https://cdmaps.polisci.ucla.edu

Silver, N. (2022, June 30). How FiveThirtyEight’s House, Senate and governor models work. *FiveThirtyEight.*  https://fivethirtyeight.com/methodology/how-fivethirtyeights-house-and-senate-models-work/

